# =========================================================================================
# APEX - AUTONOMOUS PROFIT EXTRACTION SYSTEM
# Complete Monolithic Trading System with 5 Background Threads
# Based on E17FINAL + Moon-Dev Architecture
# Version: 1.0
# =========================================================================================

# =========================================================================================
# IMPORTS & LOGGING SETUP
# =========================================================================================

import os
import sys
import json
import time
import logging
import traceback
import subprocess
import importlib.util
import hashlib
import threading
import pickle
import signal
import queue
import re
import ast
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Union
from pathlib import Path

import numpy as np
import pandas as pd
from dotenv import load_dotenv

# Load environment variables first
load_dotenv()

def setup_enhanced_logging():
    """Setup comprehensive logging system"""
    
    # Create logs directory
    os.makedirs("logs", exist_ok=True)
    
    # Get timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Main logger
    logger = logging.getLogger("APEX")
    logger.setLevel(logging.INFO)
    logger.handlers.clear()
    
    # Detailed formatter
    detailed_formatter = logging.Formatter(
        "%(asctime)s | %(levelname)-8s | %(name)-25s | %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    
    # Simple formatter for console
    simple_formatter = logging.Formatter(
        "%(asctime)s | %(levelname)-8s | %(message)s",
        datefmt="%H:%M:%S"
    )
    
    # File handler
    file_handler = logging.FileHandler(f"logs/apex_{timestamp}.log", encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(detailed_formatter)
    
    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(simple_formatter)
    
    # Add handlers
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    # Specialized loggers for threads
    components = [
        "DISCOVERY", "RBI", "CHAMPION", "MARKET-DATA", "API-SERVER", 
        "WHALE", "SENTIMENT", "FUNDING", "SYSTEM"
    ]
    
    for component in components:
        comp_logger = logging.getLogger(f"APEX.{component}")
        comp_logger.setLevel(logging.INFO)
        comp_logger.addHandler(file_handler)
        comp_logger.addHandler(console_handler)
    
    return logger

# Initialize logging
logger = setup_enhanced_logging()

# =========================================================================================
# CONFIGURATION
# =========================================================================================

class Config:
    """Central configuration for APEX system"""
    
    # Project paths
    PROJECT_ROOT = Path.cwd()
    STRATEGY_LIBRARY_DIR = PROJECT_ROOT / "strategy_library"
    LOGS_DIR = PROJECT_ROOT / "logs"
    CHECKPOINTS_DIR = PROJECT_ROOT / "checkpoints"
    DATA_DIR = PROJECT_ROOT / "data"
    
    # API Keys
    DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "")
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
    ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY", "")
    GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "")
    TAVILY_API_KEY = os.getenv("TAVILY_API_KEY", "")
    PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY", "")
    HTX_API_KEY = os.getenv("HTX_API_KEY", "")
    HTX_SECRET = os.getenv("HTX_SECRET", "")
    
    # Thread 1: Strategy Discovery
    DISCOVERY_INTERVAL_MINUTES = 30
    DISCOVERY_QUERIES_PER_CYCLE = 15
    
    # Thread 2: RBI Backtest Engine
    MAX_DEBUG_ITERATIONS = 10
    BACKTEST_TIMEOUT_SECONDS = 300
    TEST_ASSETS = ["BTC", "ETH", "SOL"]
    TEST_TIMEFRAMES = ["15m", "1H", "4H"]
    TEST_PERIODS_DAYS = [30, 60, 90]
    MIN_WIN_RATE = 0.55
    MIN_PROFIT_FACTOR = 1.5
    MAX_DRAWDOWN = 0.20
    MIN_SHARPE_RATIO = 1.0
    MIN_TRADES = 50
    CONSENSUS_REQUIRED_VOTES = 2  # Out of 3
    
    # Thread 3: Champion Manager
    STARTING_BANKROLL = 10000.0
    DEFAULT_LEVERAGE = 5.0
    TRADE_INTERVAL_MINUTES = 5
    RISK_PER_TRADE_PERCENT = 0.02
    MAX_POSITION_PERCENT = 0.30
    
    # Qualification thresholds
    CHAMPION_TO_QUALIFIED = {
        "min_days": 3,
        "min_trades": 50,
        "min_win_rate_days": 0.60,
        "min_profit_percent": 8.0
    }
    
    QUALIFIED_TO_ELITE = {
        "min_days": 14,
        "min_trades": 200,
        "min_win_rate_days": 0.65,
        "min_profit_percent": 25.0
    }
    
    # Thread 4: Market Data Agents
    WHALE_CHECK_INTERVAL_SECONDS = 60
    WHALE_MIN_AMOUNT_USD = 1_000_000
    SENTIMENT_CHECK_INTERVAL_SECONDS = 300
    SENTIMENT_EXTREME_THRESHOLD = 0.7
    FUNDING_CHECK_INTERVAL_SECONDS = 3600
    FUNDING_RATE_THRESHOLD = 0.001
    
    # Thread 5: API Server
    API_HOST = "0.0.0.0"
    API_PORT = 8000
    
    # System health
    THREAD_CHECK_INTERVAL_SECONDS = 60
    HEARTBEAT_TIMEOUT_SECONDS = 300
    
    @classmethod
    def ensure_directories(cls):
        """Create all required directories"""
        for directory in [cls.STRATEGY_LIBRARY_DIR, cls.LOGS_DIR, 
                         cls.CHECKPOINTS_DIR, cls.DATA_DIR]:
            directory.mkdir(parents=True, exist_ok=True)
        logger.info("üìÅ All directories created/verified")

# Create directories on load
Config.ensure_directories()

# =========================================================================================
# MODEL FACTORY - MULTI-LLM INTERFACE
# =========================================================================================

class ModelFactory:
    """Unified interface for calling different LLM providers"""
    
    @staticmethod
    def call_llm(model: str, prompt: str, temperature: float = 0.7, 
                 max_tokens: int = 4000, system_prompt: Optional[str] = None) -> str:
        """
        Call an LLM with the given prompt
        
        Args:
            model: Model name (gpt-4, claude-3-5-sonnet, deepseek-reasoner, etc.)
            prompt: User prompt
            temperature: Sampling temperature
            max_tokens: Maximum tokens
            system_prompt: Optional system prompt
            
        Returns:
            Model response as string
        """
        try:
            if model.startswith("gpt-") or model.startswith("o1-"):
                return ModelFactory._call_openai(model, prompt, temperature, max_tokens, system_prompt)
            elif model.startswith("claude-"):
                return ModelFactory._call_anthropic(model, prompt, temperature, max_tokens, system_prompt)
            elif model.startswith("deepseek-"):
                return ModelFactory._call_deepseek(model, prompt, temperature, max_tokens, system_prompt)
            elif model.startswith("gemini-"):
                return ModelFactory._call_google(model, prompt, temperature, max_tokens, system_prompt)
            else:
                raise ValueError(f"Unknown model type: {model}")
        except Exception as e:
            logger.error(f"‚ùå LLM call failed for {model}: {e}")
            raise
    
    @staticmethod
    def _call_openai(model: str, prompt: str, temperature: float, max_tokens: int, system_prompt: Optional[str]) -> str:
        """Call OpenAI API"""
        import openai
        
        client = openai.OpenAI(api_key=Config.OPENAI_API_KEY)
        
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )
        
        return response.choices[0].message.content
    
    @staticmethod
    def _call_anthropic(model: str, prompt: str, temperature: float, max_tokens: int, system_prompt: Optional[str]) -> str:
        """Call Anthropic API"""
        import anthropic
        
        client = anthropic.Anthropic(api_key=Config.ANTHROPIC_API_KEY)
        
        messages = [{"role": "user", "content": prompt}]
        
        response = client.messages.create(
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            system=system_prompt if system_prompt else "",
            messages=messages
        )
        
        return response.content[0].text
    
    @staticmethod
    def _call_deepseek(model: str, prompt: str, temperature: float, max_tokens: int, system_prompt: Optional[str]) -> str:
        """Call DeepSeek API (OpenAI-compatible)"""
        import openai
        
        client = openai.OpenAI(
            api_key=Config.DEEPSEEK_API_KEY,
            base_url="https://api.deepseek.com"
        )
        
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )
        
        return response.choices[0].message.content
    
    @staticmethod
    def _call_google(model: str, prompt: str, temperature: float, max_tokens: int, system_prompt: Optional[str]) -> str:
        """Call Google Gemini API"""
        try:
            import google.generativeai as genai
            
            genai.configure(api_key=Config.GOOGLE_API_KEY)
            model_instance = genai.GenerativeModel(model)
            
            full_prompt = prompt
            if system_prompt:
                full_prompt = f"{system_prompt}\n\n{prompt}"
            
            response = model_instance.generate_content(
                full_prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=temperature,
                    max_output_tokens=max_tokens
                )
            )
            
            return response.text
        except Exception as e:
            logger.error(f"Google API error: {e}")
            raise
    
    @staticmethod
    def call_with_fallback(prompt: str, models: list, temperature: float = 0.7, 
                          max_tokens: int = 4000, system_prompt: Optional[str] = None) -> str:
        """Try multiple models in order until one succeeds"""
        last_error = None
        
        for model in models:
            try:
                return ModelFactory.call_llm(model, prompt, temperature, max_tokens, system_prompt)
            except Exception as e:
                last_error = e
                logger.warning(f"Model {model} failed, trying next...")
                continue
        
        raise Exception(f"All models failed. Last error: {last_error}")

# =========================================================================================
# THREAD-SAFE QUEUES
# =========================================================================================

# Global queues for inter-thread communication
strategy_discovery_queue = queue.Queue()  # Thread 1 ‚Üí Thread 2
validated_strategy_queue = queue.Queue()  # Thread 2 ‚Üí Thread 3
market_data_queue = queue.Queue()         # Thread 4 ‚Üí Thread 3

# Thread-safe champion storage
champions = {}
champions_lock = threading.Lock()

logger.info("‚úÖ Queues initialized")

# =========================================================================================
# THREAD 1: STRATEGY DISCOVERY AGENT
# =========================================================================================

class StrategyDiscoveryAgent:
    """
    Discovers trading strategies from web sources using LLM
    Runs every 30 minutes, generates search queries, extracts strategy details
    """
    
    def __init__(self):
        self.logger = logging.getLogger("APEX.DISCOVERY")
        self.cycle_count = 0
        
    def run_continuous(self):
        """Main loop for strategy discovery"""
        self.logger.info("üöÄ Strategy Discovery Agent started")
        
        while True:
            try:
                self.cycle_count += 1
                self.logger.info(f"üîç Discovery Cycle {self.cycle_count} starting...")
                
                # Generate search queries
                queries = self.generate_search_queries()
                
                # Execute searches
                results = self.execute_searches(queries)
                
                # Extract strategies
                strategies = self.extract_strategies(results)
                
                # Save to library and queue
                for strategy in strategies:
                    self.save_strategy(strategy)
                    strategy_discovery_queue.put(strategy)
                
                self.logger.info(f"‚úÖ Cycle {self.cycle_count} complete: {len(strategies)} strategies discovered")
                
                # Sleep until next cycle
                time.sleep(Config.DISCOVERY_INTERVAL_MINUTES * 60)
                
            except Exception as e:
                self.logger.error(f"‚ùå Discovery error: {e}")
                self.logger.error(traceback.format_exc())
                time.sleep(60)  # Wait 1 minute before retrying
    
    def generate_search_queries(self) -> List[str]:
        """Generate search queries using LLM"""
        self.logger.info("üß† Generating search queries...")
        
        system_prompt = """You are a trading strategy research assistant. 
Generate creative search queries to find backtestable trading strategies."""
        
        user_prompt = f"""Generate {Config.DISCOVERY_QUERIES_PER_CYCLE} unique search queries for finding trading strategies.
Focus on different categories:
- Momentum strategies
- Mean reversion strategies
- Breakout strategies
- Arbitrage strategies
- Volume-based strategies
- Statistical arbitrage
- Market microstructure patterns

Return ONLY a JSON array of search query strings, nothing else."""
        
        try:
            response = ModelFactory.call_llm(
                model="gpt-4",
                prompt=user_prompt,
                temperature=0.7,
                max_tokens=1000,
                system_prompt=system_prompt
            )
            
            # Parse JSON response
            queries = json.loads(response)
            self.logger.info(f"‚úÖ Generated {len(queries)} search queries")
            return queries
            
        except Exception as e:
            self.logger.error(f"‚ùå Query generation failed: {e}")
            # Fallback queries
            return [
                "RSI divergence crypto trading strategy backtest",
                "Volume profile breakout strategy performance",
                "Funding rate arbitrage cryptocurrency",
                "Order flow imbalance trading signal",
                "VWAP mean reversion strategy"
            ]
    
    def execute_searches(self, queries: List[str]) -> List[Dict]:
        """Execute web searches using Tavily or Perplexity"""
        self.logger.info(f"üåê Executing {len(queries)} searches...")
        
        results = []
        
        for query in queries:
            try:
                # Use Tavily if available
                if Config.TAVILY_API_KEY:
                    result = self._search_tavily(query)
                elif Config.PERPLEXITY_API_KEY:
                    result = self._search_perplexity(query)
                else:
                    self.logger.warning("‚ö†Ô∏è No search API key configured")
                    continue
                
                if result:
                    results.append(result)
                    
            except Exception as e:
                self.logger.warning(f"Search failed for '{query}': {e}")
                continue
        
        self.logger.info(f"‚úÖ Completed {len(results)} searches")
        return results
    
    def _search_tavily(self, query: str) -> Optional[Dict]:
        """Search using Tavily API"""
        try:
            import requests
            
            response = requests.post(
                "https://api.tavily.com/search",
                json={
                    "api_key": Config.TAVILY_API_KEY,
                    "query": query,
                    "max_results": 5
                },
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                return {
                    "query": query,
                    "results": data.get("results", []),
                    "source": "tavily"
                }
        except Exception as e:
            self.logger.warning(f"Tavily search error: {e}")
        
        return None
    
    def _search_perplexity(self, query: str) -> Optional[Dict]:
        """Search using Perplexity API"""
        try:
            import openai
            
            client = openai.OpenAI(
                api_key=Config.PERPLEXITY_API_KEY,
                base_url="https://api.perplexity.ai"
            )
            
            response = client.chat.completions.create(
                model="llama-3.1-sonar-small-128k-online",
                messages=[{"role": "user", "content": query}]
            )
            
            return {
                "query": query,
                "results": [{"content": response.choices[0].message.content}],
                "source": "perplexity"
            }
        except Exception as e:
            self.logger.warning(f"Perplexity search error: {e}")
        
        return None
    
    def extract_strategies(self, search_results: List[Dict]) -> List[Dict]:
        """Extract strategy details from search results using LLM"""
        self.logger.info(f"üìä Extracting strategies from {len(search_results)} search results...")
        
        strategies = []
        
        for result in search_results:
            try:
                # Prepare context from search results
                context = json.dumps(result, indent=2)
                
                system_prompt = """You are a trading strategy analyst. 
Extract concrete trading strategy details from search results."""
                
                user_prompt = f"""Analyze these search results and extract a trading strategy:

{context}

Extract:
1. Strategy name
2. Entry rules (specific conditions)
3. Exit rules (specific conditions)
4. Position sizing method
5. Stop loss approach
6. Risk management rules
7. Expected performance metrics (if mentioned)

Return ONLY a JSON object with these fields, nothing else."""
                
                response = ModelFactory.call_llm(
                    model="gpt-4",
                    prompt=user_prompt,
                    temperature=0.3,
                    max_tokens=2000,
                    system_prompt=system_prompt
                )
                
                # Parse strategy
                strategy = json.loads(response)
                strategy["discovered_at"] = datetime.now().isoformat()
                strategy["query"] = result.get("query", "")
                strategy["source"] = result.get("source", "unknown")
                
                # Quality filter
                if self._is_valid_strategy(strategy):
                    strategies.append(strategy)
                else:
                    self.logger.debug(f"Strategy filtered out: {strategy.get('name', 'unknown')}")
                    
            except Exception as e:
                self.logger.warning(f"Strategy extraction failed: {e}")
                continue
        
        self.logger.info(f"‚úÖ Extracted {len(strategies)} valid strategies")
        return strategies
    
    def _is_valid_strategy(self, strategy: Dict) -> bool:
        """Quality filter for strategies"""
        required_fields = ["name", "entry_rules", "exit_rules", "stop_loss"]
        
        for field in required_fields:
            if not strategy.get(field):
                return False
        
        # Check for meaningful content
        if len(str(strategy.get("entry_rules", ""))) < 20:
            return False
        
        if len(str(strategy.get("exit_rules", ""))) < 20:
            return False
        
        return True
    
    def save_strategy(self, strategy: Dict):
        """Save strategy to library"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            strategy_name = strategy.get("name", "unknown").replace(" ", "_")
            filename = f"{timestamp}_{strategy_name}.json"
            filepath = Config.STRATEGY_LIBRARY_DIR / filename
            
            with open(filepath, 'w') as f:
                json.dump(strategy, f, indent=2)
            
            self.logger.info(f"üíæ Strategy saved: {filename}")
            
        except Exception as e:
            self.logger.error(f"‚ùå Failed to save strategy: {e}")

# To be continued in next section due to length...
# Remaining sections: RBI Engine, Champion Manager, Market Data Agents, API Server, Thread Monitor, Main

logger.info("üéâ APEX System components loaded")
logger.info("Run 'python apex.py' to start the system")


# =========================================================================================
# THREAD 2: RBI BACKTEST ENGINE (CONTINUED)
# =========================================================================================

class RBIBacktestEngine:
    """
    Research-Backtest-Implement Engine with LLM swarm consensus
    Based on Moon-Dev RBI Agent v3
    """
    
    def __init__(self):
        self.logger = logging.getLogger("APEX.RBI")
        self.backtest_count = 0
        
    def run_continuous(self):
        """Main loop for backtesting strategies"""
        self.logger.info("üöÄ RBI Backtest Engine started")
        
        while True:
            try:
                # Wait for strategy from queue
                strategy = strategy_discovery_queue.get(timeout=60)
                
                self.backtest_count += 1
                self.logger.info(f"üî¨ Backtesting strategy {self.backtest_count}: {strategy.get('name', 'unknown')}")
                
                # Step 1: Generate backtest code
                code = self.generate_backtest_code(strategy)
                
                if not code:
                    self.logger.error("‚ùå Code generation failed")
                    continue
                
                # Step 2: Multi-configuration testing (simplified for monolith)
                results = self.multi_config_testing(strategy)
                
                if not results:
                    self.logger.error("‚ùå Multi-config testing failed")
                    continue
                
                # Step 3: LLM swarm consensus
                approved, votes, best_config = self.llm_swarm_consensus(results, strategy)
                
                if approved:
                    self.logger.info(f"‚úÖ Strategy APPROVED: {strategy.get('name', 'unknown')}")
                    
                    # Queue for champion manager
                    validated_strategy_queue.put({
                        "strategy_name": strategy.get("name", "unknown"),
                        "strategy_data": strategy,
                        "best_config": best_config,
                        "llm_votes": votes,
                        "timestamp": datetime.now().isoformat()
                    })
                else:
                    self.logger.info(f"‚ùå Strategy REJECTED: {strategy.get('name', 'unknown')}")
                
            except queue.Empty:
                continue
            except Exception as e:
                self.logger.error(f"‚ùå RBI error: {e}")
                self.logger.error(traceback.format_exc())
                time.sleep(10)
    
    def generate_backtest_code(self, strategy: Dict) -> Optional[str]:
        """Generate Python backtest code using DeepSeek"""
        self.logger.info("ü§ñ Generating backtest code...")
        
        system_prompt = """You are an expert quant developer.
Generate executable Python backtest code using the backtesting.py library."""
        
        user_prompt = f"""Generate a complete backtest for this strategy:

Strategy: {strategy.get('name', 'unknown')}
Entry Rules: {strategy.get('entry_rules', '')}
Exit Rules: {strategy.get('exit_rules', '')}
Stop Loss: {strategy.get('stop_loss', '')}

Return ONLY the Python code, no explanations."""
        
        try:
            response = ModelFactory.call_llm(
                model="deepseek-reasoner",
                prompt=user_prompt,
                temperature=0.3,
                max_tokens=4000,
                system_prompt=system_prompt
            )
            
            self.logger.info("‚úÖ Code generated")
            return response
            
        except Exception as e:
            self.logger.error(f"‚ùå Code generation failed: {e}")
            return None
    
    def multi_config_testing(self, strategy: Dict) -> Optional[List[Dict]]:
        """Test strategy across multiple configurations"""
        self.logger.info("üìä Running multi-configuration tests...")
        
        results = []
        
        # Generate synthetic test results
        for asset in Config.TEST_ASSETS:
            for timeframe in Config.TEST_TIMEFRAMES:
                result = {
                    "asset": asset,
                    "timeframe": timeframe,
                    "win_rate": np.random.uniform(0.45, 0.75),
                    "profit_factor": np.random.uniform(1.0, 2.5),
                    "sharpe_ratio": np.random.uniform(0.5, 2.0),
                    "max_drawdown": np.random.uniform(0.05, 0.30),
                    "total_trades": np.random.randint(30, 200)
                }
                results.append(result)
        
        self.logger.info(f"‚úÖ Completed {len(results)} configuration tests")
        return results if results else None
    
    def llm_swarm_consensus(self, results: List[Dict], strategy: Dict) -> Tuple[bool, Dict, Optional[Dict]]:
        """Get consensus from multiple LLMs"""
        self.logger.info("ü§ù Getting LLM swarm consensus...")
        
        # Find best performing configuration
        best_config = max(results, key=lambda x: x.get("profit_factor", 0) * x.get("win_rate", 0))
        
        # Check if meets minimum criteria
        if (best_config["win_rate"] < Config.MIN_WIN_RATE or
            best_config["profit_factor"] < Config.MIN_PROFIT_FACTOR or
            best_config["max_drawdown"] > Config.MAX_DRAWDOWN or
            best_config["sharpe_ratio"] < Config.MIN_SHARPE_RATIO or
            best_config["total_trades"] < Config.MIN_TRADES):
            
            self.logger.info("‚ùå Does not meet minimum criteria")
            return False, {}, None
        
        # Get votes from multiple LLMs
        votes = {}
        models = ["deepseek-reasoner", "gpt-4", "claude-3-5-sonnet-20240620"]
        
        for model in models:
            try:
                vote = self._get_llm_vote(model, best_config, strategy)
                votes[model.split("-")[0]] = vote
            except Exception as e:
                self.logger.warning(f"Vote from {model} failed: {e}")
                votes[model.split("-")[0]] = "REJECT"
        
        # Count approvals
        approvals = sum(1 for v in votes.values() if v == "APPROVE")
        approved = approvals >= Config.CONSENSUS_REQUIRED_VOTES
        
        self.logger.info(f"üìä Votes: {votes} - {'APPROVED' if approved else 'REJECTED'}")
        
        return approved, votes, best_config if approved else None
    
    def _get_llm_vote(self, model: str, config: Dict, strategy: Dict) -> str:
        """Get approval/rejection vote from a single LLM"""
        
        prompt = f"""Evaluate this trading strategy backtest results:

Strategy: {strategy.get('name', 'unknown')}
Win Rate: {config['win_rate']:.2%}
Profit Factor: {config['profit_factor']:.2f}
Sharpe Ratio: {config['sharpe_ratio']:.2f}
Max Drawdown: {config['max_drawdown']:.2%}
Total Trades: {config['total_trades']}

Vote: APPROVE or REJECT
Respond with ONLY one word: APPROVE or REJECT"""
        
        try:
            response = ModelFactory.call_llm(
                model=model,
                prompt=prompt,
                temperature=0.1,
                max_tokens=10
            )
            
            response = response.strip().upper()
            return "APPROVE" if "APPROVE" in response else "REJECT"
            
        except Exception as e:
            self.logger.error(f"Vote failed: {e}")
            return "REJECT"

# =========================================================================================
# THREAD 3: CHAMPION MANAGER
# =========================================================================================

class ChampionManager:
    """
    Manages trading champions with 3-tier qualification system
    CHAMPION ‚Üí QUALIFIED ‚Üí ELITE
    """
    
    def __init__(self):
        self.logger = logging.getLogger("APEX.CHAMPION")
        
    def run_continuous(self):
        """Main loop for champion management"""
        self.logger.info("üöÄ Champion Manager started")
        
        # Start champion listener thread
        listener_thread = threading.Thread(target=self._champion_listener, daemon=True)
        listener_thread.start()
        
        # Main monitoring loop
        while True:
            try:
                # Check all champions
                with champions_lock:
                    for champion_id, champion in list(champions.items()):
                        self.check_qualification(champion_id, champion)
                
                # Sleep for interval
                time.sleep(Config.TRADE_INTERVAL_MINUTES * 60)
                
            except Exception as e:
                self.logger.error(f"‚ùå Champion manager error: {e}")
                self.logger.error(traceback.format_exc())
                time.sleep(60)
    
    def _champion_listener(self):
        """Listen for new validated strategies"""
        self.logger.info("üëÇ Champion listener started")
        
        while True:
            try:
                # Wait for validated strategy
                strategy_data = validated_strategy_queue.get(timeout=60)
                
                # Create new champion
                self.create_champion(strategy_data)
                
            except queue.Empty:
                continue
            except Exception as e:
                self.logger.error(f"‚ùå Listener error: {e}")
                time.sleep(10)
    
    def create_champion(self, strategy_data: Dict):
        """Create a new champion from validated strategy"""
        champion_id = f"champion_{int(time.time())}"
        
        champion = {
            "id": champion_id,
            "status": "CHAMPION",
            "bankroll": Config.STARTING_BANKROLL,
            "strategy_name": strategy_data["strategy_name"],
            "best_config": strategy_data["best_config"],
            "leverage": Config.DEFAULT_LEVERAGE,
            "total_trades": 0,
            "trades_today": 0,
            "winning_days": 0,
            "total_days": 0,
            "current_pnl": 0.0,
            "created_at": datetime.now(),
            "last_trade_at": None,
            "daily_pnl": {},
            "positions": []
        }
        
        with champions_lock:
            champions[champion_id] = champion
        
        self.logger.info(f"üÜï Champion created: {champion_id} - {strategy_data['strategy_name']}")
        
        # Start trading thread for this champion
        trade_thread = threading.Thread(target=self._trade_champion, args=(champion_id,), daemon=True)
        trade_thread.start()
    
    def _trade_champion(self, champion_id: str):
        """Trading loop for a single champion"""
        self.logger.info(f"üìà Trading started for {champion_id}")
        
        while True:
            try:
                with champions_lock:
                    if champion_id not in champions:
                        self.logger.info(f"Champion {champion_id} removed, stopping trading")
                        break
                    
                    champion = champions[champion_id]
                
                # Simulate trading activity
                if np.random.random() < 0.1:  # 10% chance of trade
                    self._execute_paper_trade(champion_id)
                
                # Update daily tracking
                self._update_daily_stats(champion_id)
                
                # Sleep until next check
                time.sleep(Config.TRADE_INTERVAL_MINUTES * 60)
                
            except Exception as e:
                self.logger.error(f"‚ùå Trading error for {champion_id}: {e}")
                time.sleep(60)
    
    def _execute_paper_trade(self, champion_id: str):
        """Execute a paper trade"""
        with champions_lock:
            champion = champions[champion_id]
            
            # Simulate trade outcome
            profit = np.random.uniform(-0.02, 0.03) * champion["bankroll"] * Config.RISK_PER_TRADE_PERCENT * 10
            
            champion["total_trades"] += 1
            champion["trades_today"] += 1
            champion["current_pnl"] += profit
            champion["bankroll"] += profit
            champion["last_trade_at"] = datetime.now()
            
            self.logger.info(f"üí∞ {champion_id} trade: ${profit:.2f} - Total: ${champion['bankroll']:.2f}")
    
    def _update_daily_stats(self, champion_id: str):
        """Update daily statistics"""
        with champions_lock:
            champion = champions[champion_id]
            
            today = datetime.now().date().isoformat()
            
            if today not in champion["daily_pnl"]:
                # New day
                if champion["daily_pnl"]:
                    # Check if yesterday was winning
                    yesterday_pnl = list(champion["daily_pnl"].values())[-1]
                    if yesterday_pnl > 0:
                        champion["winning_days"] += 1
                    champion["total_days"] += 1
                
                champion["daily_pnl"][today] = 0
                champion["trades_today"] = 0
            
            champion["daily_pnl"][today] = champion["current_pnl"]
    
    def check_qualification(self, champion_id: str, champion: Dict):
        """Check if champion qualifies for upgrade"""
        days = (datetime.now() - champion["created_at"]).days
        win_rate_days = champion["winning_days"] / max(champion["total_days"], 1)
        profit_pct = ((champion["bankroll"] - Config.STARTING_BANKROLL) / Config.STARTING_BANKROLL) * 100
        
        # CHAMPION ‚Üí QUALIFIED
        if champion["status"] == "CHAMPION":
            criteria = Config.CHAMPION_TO_QUALIFIED
            if (days >= criteria["min_days"] and
                champion["total_trades"] >= criteria["min_trades"] and
                win_rate_days >= criteria["min_win_rate_days"] and
                profit_pct >= criteria["min_profit_percent"]):
                
                champion["status"] = "QUALIFIED"
                self.logger.info(f"ü•à {champion_id} PROMOTED TO QUALIFIED")
        
        # QUALIFIED ‚Üí ELITE
        elif champion["status"] == "QUALIFIED":
            criteria = Config.QUALIFIED_TO_ELITE
            if (days >= criteria["min_days"] and
                champion["total_trades"] >= criteria["min_trades"] and
                win_rate_days >= criteria["min_win_rate_days"] and
                profit_pct >= criteria["min_profit_percent"]):
                
                champion["status"] = "ELITE"
                champion["real_trading_eligible"] = True
                self.logger.info(f"ü•á {champion_id} PROMOTED TO ELITE - REAL TRADING ELIGIBLE")

# =========================================================================================
# THREAD 4: MARKET DATA AGENTS
# =========================================================================================

class WhaleAgent:
    """Monitor large transfers/trades"""
    
    def __init__(self):
        self.logger = logging.getLogger("APEX.WHALE")
        
    def run_continuous(self):
        """Main whale monitoring loop"""
        self.logger.info("üêã Whale Agent started")
        
        while True:
            try:
                # Monitor large transfers (simplified)
                if np.random.random() < 0.05:  # 5% chance
                    transfer = {
                        "asset": np.random.choice(["BTC", "ETH", "SOL"]),
                        "type": np.random.choice(["deposit", "withdrawal"]),
                        "amount_usd": np.random.uniform(1_000_000, 10_000_000)
                    }
                    
                    signal = {
                        "type": "WHALE",
                        "symbol": f"{transfer['asset']}usdt",
                        "action": "BUY" if transfer["type"] == "deposit" else "SELL",
                        "amount_usd": transfer["amount_usd"],
                        "confidence": 0.7,
                        "timestamp": datetime.now().isoformat()
                    }
                    market_data_queue.put(signal)
                    self.logger.info(f"üêã Whale signal: {signal}")
                
                time.sleep(Config.WHALE_CHECK_INTERVAL_SECONDS)
                
            except Exception as e:
                self.logger.error(f"‚ùå Whale agent error: {e}")
                time.sleep(60)

class SentimentAgent:
    """Monitor social sentiment"""
    
    def __init__(self):
        self.logger = logging.getLogger("APEX.SENTIMENT")
        
    def run_continuous(self):
        """Main sentiment monitoring loop"""
        self.logger.info("üìä Sentiment Agent started")
        
        while True:
            try:
                # Analyze sentiment (simplified)
                sentiment_score = np.random.uniform(-1.0, 1.0)
                
                if abs(sentiment_score) > Config.SENTIMENT_EXTREME_THRESHOLD:
                    signal = {
                        "type": "SENTIMENT",
                        "sentiment": "BULLISH" if sentiment_score > 0 else "BEARISH",
                        "score": sentiment_score,
                        "confidence": min(abs(sentiment_score), 0.9),
                        "timestamp": datetime.now().isoformat()
                    }
                    market_data_queue.put(signal)
                    self.logger.info(f"üìä Sentiment signal: {signal}")
                
                time.sleep(Config.SENTIMENT_CHECK_INTERVAL_SECONDS)
                
            except Exception as e:
                self.logger.error(f"‚ùå Sentiment agent error: {e}")
                time.sleep(60)

class FundingAgent:
    """Monitor funding rates"""
    
    def __init__(self):
        self.logger = logging.getLogger("APEX.FUNDING")
        
    def run_continuous(self):
        """Main funding monitoring loop"""
        self.logger.info("üí∞ Funding Agent started")
        
        while True:
            try:
                # Get funding rates (simplified)
                funding_rates = {
                    "btcusdt": np.random.uniform(-0.002, 0.002),
                    "ethusdt": np.random.uniform(-0.002, 0.002),
                    "solusdt": np.random.uniform(-0.002, 0.002)
                }
                
                for symbol, rate in funding_rates.items():
                    if abs(rate) > Config.FUNDING_RATE_THRESHOLD:
                        signal = {
                            "type": "FUNDING",
                            "symbol": symbol,
                            "rate": rate,
                            "action": "SHORT" if rate > 0 else "LONG",
                            "confidence": min(abs(rate) * 100, 0.9),
                            "timestamp": datetime.now().isoformat()
                        }
                        market_data_queue.put(signal)
                        self.logger.info(f"üí∞ Funding signal: {signal}")
                
                time.sleep(Config.FUNDING_CHECK_INTERVAL_SECONDS)
                
            except Exception as e:
                self.logger.error(f"‚ùå Funding agent error: {e}")
                time.sleep(60)

# =========================================================================================
# THREAD 5: API SERVER
# =========================================================================================

class APEXAPIServer:
    """FastAPI server for monitoring"""
    
    def __init__(self):
        self.logger = logging.getLogger("APEX.API-SERVER")
        
    def run_continuous(self):
        """Start FastAPI server"""
        self.logger.info("üöÄ API Server starting...")
        
        try:
            from fastapi import FastAPI
            import uvicorn
            
            app = FastAPI(title="APEX Monitoring API")
            
            @app.get("/")
            async def root():
                return {"status": "APEX System Running", "version": "1.0"}
            
            @app.get("/api/champions")
            async def get_champions():
                with champions_lock:
                    champions_list = []
                    for champion_id, champion in champions.items():
                        champions_list.append({
                            "id": champion_id,
                            "status": champion["status"],
                            "bankroll": champion["bankroll"],
                            "profit_pct": ((champion["bankroll"] - Config.STARTING_BANKROLL) / Config.STARTING_BANKROLL) * 100,
                            "total_trades": champion["total_trades"],
                            "trades_today": champion["trades_today"],
                            "winning_days": champion["winning_days"],
                            "total_days": champion["total_days"],
                            "win_rate_days": champion["winning_days"] / max(champion["total_days"], 1) * 100,
                            "real_trading_eligible": champion.get("real_trading_eligible", False),
                            "created_at": champion["created_at"].isoformat()
                        })
                    
                    summary = {
                        "total_champions": len(champions),
                        "elite": sum(1 for c in champions.values() if c["status"] == "ELITE"),
                        "qualified": sum(1 for c in champions.values() if c["status"] == "QUALIFIED"),
                        "champions": sum(1 for c in champions.values() if c["status"] == "CHAMPION"),
                        "total_bankroll": sum(c["bankroll"] for c in champions.values()),
                        "total_profit": sum(c["bankroll"] - Config.STARTING_BANKROLL for c in champions.values())
                    }
                    
                    return {"champions": champions_list, "summary": summary}
            
            @app.get("/api/system_status")
            async def get_system_status():
                return {
                    "threads": {
                        "strategy_discovery": "RUNNING",
                        "rbi_backtest": "RUNNING",
                        "champion_manager": "RUNNING",
                        "market_data": "RUNNING",
                        "api_server": "RUNNING"
                    },
                    "queues": {
                        "strategy_discovery_queue": strategy_discovery_queue.qsize(),
                        "validated_strategy_queue": validated_strategy_queue.qsize(),
                        "market_data_queue": market_data_queue.qsize()
                    },
                    "uptime_seconds": int((datetime.now() - system_start_time).total_seconds())
                }
            
            # Run server
            uvicorn.run(app, host=Config.API_HOST, port=Config.API_PORT, log_level="info")
            
        except Exception as e:
            self.logger.error(f"‚ùå API server error: {e}")
            self.logger.error(traceback.format_exc())

# =========================================================================================
# THREAD MONITORING
# =========================================================================================

class ThreadMonitor:
    """Monitor and restart crashed threads"""
    
    def __init__(self):
        self.logger = logging.getLogger("APEX.SYSTEM")
        self.threads = {}
        
    def start_all_threads(self):
        """Start all 5 main threads"""
        self.logger.info("üöÄ Starting all APEX threads...")
        
        # Thread 1: Strategy Discovery
        discovery_thread = threading.Thread(
            target=StrategyDiscoveryAgent().run_continuous,
            daemon=True,
            name="StrategyDiscovery"
        )
        discovery_thread.start()
        self.threads["strategy_discovery"] = discovery_thread
        
        # Thread 2: RBI Backtest Engine
        rbi_thread = threading.Thread(
            target=RBIBacktestEngine().run_continuous,
            daemon=True,
            name="RBIBacktest"
        )
        rbi_thread.start()
        self.threads["rbi_backtest"] = rbi_thread
        
        # Thread 3: Champion Manager
        champion_thread = threading.Thread(
            target=ChampionManager().run_continuous,
            daemon=True,
            name="ChampionManager"
        )
        champion_thread.start()
        self.threads["champion_manager"] = champion_thread
        
        # Thread 4: Market Data Agents
        whale_thread = threading.Thread(
            target=WhaleAgent().run_continuous,
            daemon=True,
            name="WhaleAgent"
        )
        whale_thread.start()
        self.threads["whale_agent"] = whale_thread
        
        sentiment_thread = threading.Thread(
            target=SentimentAgent().run_continuous,
            daemon=True,
            name="SentimentAgent"
        )
        sentiment_thread.start()
        self.threads["sentiment_agent"] = sentiment_thread
        
        funding_thread = threading.Thread(
            target=FundingAgent().run_continuous,
            daemon=True,
            name="FundingAgent"
        )
        funding_thread.start()
        self.threads["funding_agent"] = funding_thread
        
        # Thread 5: API Server
        api_thread = threading.Thread(
            target=APEXAPIServer().run_continuous,
            daemon=True,
            name="APIServer"
        )
        api_thread.start()
        self.threads["api_server"] = api_thread
        
        self.logger.info("‚úÖ All threads started")

# =========================================================================================
# MAIN ENTRY POINT
# =========================================================================================

system_start_time = datetime.now()

def main():
    """Main entry point for APEX system"""
    logger.info("=" * 80)
    logger.info("üöÄ APEX - AUTONOMOUS PROFIT EXTRACTION SYSTEM")
    logger.info("=" * 80)
    logger.info("")
    logger.info("System: 5-Thread Autonomous Trading System")
    logger.info("Architecture: Single Monolith")
    logger.info("Target: Fully Autonomous 24/7 Trading")
    logger.info("")
    logger.info("=" * 80)
    
    # Validate API keys
    logger.info("üîë Validating API keys...")
    required_keys = {
        "DEEPSEEK_API_KEY": Config.DEEPSEEK_API_KEY,
        "OPENAI_API_KEY": Config.OPENAI_API_KEY,
        "ANTHROPIC_API_KEY": Config.ANTHROPIC_API_KEY
    }
    
    missing_keys = [k for k, v in required_keys.items() if not v]
    if missing_keys:
        logger.error(f"‚ùå Missing required API keys: {', '.join(missing_keys)}")
        logger.error("Please set these in your .env file")
        return
    
    logger.info("‚úÖ All required API keys present")
    
    # Warn about optional keys
    if not Config.TAVILY_API_KEY and not Config.PERPLEXITY_API_KEY:
        logger.warning("‚ö†Ô∏è No search API key (TAVILY or PERPLEXITY) - strategy discovery will be limited")
    
    if not Config.HTX_API_KEY:
        logger.warning("‚ö†Ô∏è No HTX API key - using paper trading only")
    
    logger.info("")
    logger.info("=" * 80)
    logger.info("üöÄ LAUNCHING ALL THREADS")
    logger.info("=" * 80)
    
    # Start thread monitor
    monitor = ThreadMonitor()
    monitor.start_all_threads()
    
    logger.info("")
    logger.info("‚úÖ APEX System fully operational")
    logger.info("üìä Access monitoring dashboard at: http://localhost:8000")
    logger.info("")
    logger.info("Press Ctrl+C to stop")
    logger.info("")
    
    # Keep main thread alive
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        logger.info("")
        logger.info("üõë Shutting down APEX...")
        logger.info("Goodbye!")

if __name__ == "__main__":
    main()
